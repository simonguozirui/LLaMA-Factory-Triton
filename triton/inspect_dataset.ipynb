{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/matx/u/simonguo/triton_sft_data/pytorch_scrape_github_inductor_data_alpaca_inst_5000_samples.json\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(dataset_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   instruction  5000 non-null   object\n",
      " 1   input        5000 non-null   object\n",
      " 2   output       5000 non-null   object\n",
      " 3   entry_point  5000 non-null   object\n",
      " 4   uuid         5000 non-null   int64 \n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 195.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>entry_point</th>\n",
       "      <th>uuid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You write custom Triton kernels to replace the...</td>\n",
       "      <td>import torch\\nimport torch.nn as nn\\n\\n\\nclass...</td>\n",
       "      <td>import torch\\nimport triton\\nimport triton.lan...</td>\n",
       "      <td>SumAggregator</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You write custom Triton kernels to replace the...</td>\n",
       "      <td>import math\\nimport torch\\nimport torch.utils....</td>\n",
       "      <td>import torch\\nfrom torch._inductor.select_algo...</td>\n",
       "      <td>LinearEmbedding</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You write custom Triton kernels to replace the...</td>\n",
       "      <td>import torch\\nimport torch.nn as nn\\n\\n\\nclass...</td>\n",
       "      <td>import torch\\nimport triton\\nimport triton.lan...</td>\n",
       "      <td>CustomizeLayer</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You write custom Triton kernels to replace the...</td>\n",
       "      <td>import torch\\nimport torch.nn as nn\\n\\n\\nclass...</td>\n",
       "      <td>import torch\\nimport triton\\nimport triton.lan...</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You write custom Triton kernels to replace the...</td>\n",
       "      <td>import torch\\nimport torch.utils.data\\nimport ...</td>\n",
       "      <td>import torch\\nimport triton\\nimport triton.lan...</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         instruction  \\\n",
       "0  You write custom Triton kernels to replace the...   \n",
       "1  You write custom Triton kernels to replace the...   \n",
       "2  You write custom Triton kernels to replace the...   \n",
       "3  You write custom Triton kernels to replace the...   \n",
       "4  You write custom Triton kernels to replace the...   \n",
       "\n",
       "                                               input  \\\n",
       "0  import torch\\nimport torch.nn as nn\\n\\n\\nclass...   \n",
       "1  import math\\nimport torch\\nimport torch.utils....   \n",
       "2  import torch\\nimport torch.nn as nn\\n\\n\\nclass...   \n",
       "3  import torch\\nimport torch.nn as nn\\n\\n\\nclass...   \n",
       "4  import torch\\nimport torch.utils.data\\nimport ...   \n",
       "\n",
       "                                              output      entry_point  uuid  \n",
       "0  import torch\\nimport triton\\nimport triton.lan...    SumAggregator     0  \n",
       "1  import torch\\nfrom torch._inductor.select_algo...  LinearEmbedding     1  \n",
       "2  import torch\\nimport triton\\nimport triton.lan...   CustomizeLayer     2  \n",
       "3  import torch\\nimport triton\\nimport triton.lan...        LayerNorm     3  \n",
       "4  import torch\\nimport triton\\nimport triton.lan...        LayerNorm     4  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "instruction    You write custom Triton kernels to replace the...\n",
       "input          import torch\\nimport torch.nn as nn\\n\\n\\nclass...\n",
       "output         import torch\\nimport triton\\nimport triton.lan...\n",
       "entry_point                                        SumAggregator\n",
       "uuid                                                           0\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_row = df.iloc[0]\n",
    "first_row\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You write custom Triton kernels to replace the pytorch operators in the given architecture to get speedups.\n",
      "\n",
      "You have complete freedom to choose the set of operators you want to replace. You may make the decision to replace some operators with custom Triton kernels and leave others unchanged. You may replace multiple operators with custom implementations, consider operator fusion opportunities (combining multiple operators into a single kernel, for example, combining matmul+relu), or algorithmic changes (such as online softmax). You are only limited by your imagination.\n",
      "\n",
      "Optimize the architecture named SumAggregator with custom Triton kernels! Name your optimized output architecture SumAggregatorNew. Output the new code in codeblocks. \n",
      "Please generate real code, NOT pseudocode, make sure the code compiles and is fully functional. Just output the new model code, no other text, and NO testing code! \n",
      "\n",
      "            \n",
      "You are given the following architecture: \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(first_row[\"instruction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import torch\n",
      "import torch.nn as nn\n",
      "\n",
      "\n",
      "class SumAggregator(nn.Module):\n",
      "\n",
      "    def __init__(self):\n",
      "        super(SumAggregator, self).__init__()\n",
      "\n",
      "    def forward(self, neighbor):\n",
      "        return torch.sum(neighbor, dim=1)\n",
      "\n",
      "\n",
      "def get_inputs():\n",
      "    return [torch.rand([4, 4, 4, 4])]\n",
      "\n",
      "\n",
      "def get_init_inputs():\n",
      "    return [[], {}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(first_row[\"input\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import torch\n",
      "import triton\n",
      "import triton.language as tl\n",
      "from torch._inductor.runtime.triton_heuristics import grid\n",
      "from torch._C import _cuda_getCurrentRawStream as get_raw_stream\n",
      "import torch.nn as nn\n",
      "assert_size_stride = torch._C._dynamo.guards.assert_size_stride\n",
      "empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda\n",
      "\n",
      "\n",
      "@triton.jit\n",
      "def triton_poi_fused_sum_0(in_ptr0, out_ptr0, xnumel, XBLOCK: tl.constexpr):\n",
      "    xnumel = 64\n",
      "    xoffset = tl.program_id(0) * XBLOCK\n",
      "    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n",
      "    xmask = xindex < xnumel\n",
      "    x0 = xindex % 16\n",
      "    x1 = xindex // 16\n",
      "    x2 = xindex\n",
      "    tmp0 = tl.load(in_ptr0 + (x0 + 64 * x1), xmask)\n",
      "    tmp1 = tl.load(in_ptr0 + (16 + x0 + 64 * x1), xmask)\n",
      "    tmp3 = tl.load(in_ptr0 + (32 + x0 + 64 * x1), xmask)\n",
      "    tmp5 = tl.load(in_ptr0 + (48 + x0 + 64 * x1), xmask)\n",
      "    tmp2 = tmp0 + tmp1\n",
      "    tmp4 = tmp2 + tmp3\n",
      "    tmp6 = tmp4 + tmp5\n",
      "    tl.store(out_ptr0 + x2, tmp6, xmask)\n",
      "\n",
      "\n",
      "def call(args):\n",
      "    arg0_1, = args\n",
      "    args.clear()\n",
      "    assert_size_stride(arg0_1, (4, 4, 4, 4), (64, 16, 4, 1))\n",
      "    with torch.cuda._DeviceGuard(0):\n",
      "        torch.cuda.set_device(0)\n",
      "        buf0 = empty_strided_cuda((4, 4, 4), (16, 4, 1), torch.float32)\n",
      "        get_raw_stream(0)\n",
      "        triton_poi_fused_sum_0[grid(64)](arg0_1, buf0, 64, XBLOCK=64,\n",
      "            num_warps=1, num_stages=1)\n",
      "        del arg0_1\n",
      "    return buf0,\n",
      "\n",
      "\n",
      "class SumAggregatorNew(nn.Module):\n",
      "\n",
      "    def __init__(self):\n",
      "        super(SumAggregatorNew, self).__init__()\n",
      "\n",
      "    def forward(self, input_0):\n",
      "        arg0_1 = input_0\n",
      "        output = call([arg0_1])\n",
      "        return output[0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(first_row[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_factory_sft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
